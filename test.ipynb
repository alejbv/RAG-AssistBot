{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic modules\n",
    "import numpy as np\n",
    "import ir_datasets\n",
    "# The model modules\n",
    "from libs.lexical_retriever import LexicalRetriever\n",
    "from libs.vector_retriever import VectorRetriever\n",
    "from libs.hybrid_retriever import HybridRetriever\n",
    "from libs.basic_document_storage import BasicStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the dataset\n",
    "# Loading the dataset\n",
    "dataset = ir_datasets.load(\"cranfield\")\n",
    "# Preparing the docs and queries\n",
    "prep_funct = lambda x: dict(doc_id=x[0],title=x[1],text=x[2],author=x[3],bib=x[4])\n",
    "docs = [doc for doc in map(prep_funct,dataset.docs_iter()) if len(doc['text'])]\n",
    "queries = {query[0]:query[1] for query in dataset.queries_iter()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the Indexer\n",
    "index = BasicStorage()\n",
    "# Adding the documents\n",
    "index.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the retrievers\n",
    "vector = VectorRetriever()\n",
    "lexical = LexicalRetriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_thread.RLock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Preparing the hybrid retrieval\u001b[39;00m\n\u001b[1;32m      2\u001b[0m retriever \u001b[38;5;241m=\u001b[39m HybridRetriever(documents_\u001b[38;5;241m=\u001b[39mindex, retrievers\u001b[38;5;241m=\u001b[39m[vector])\n\u001b[0;32m----> 3\u001b[0m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/alejbv/Disco1/HDD Old/Carrerra/Mis Temas/DL,NLP,SRI,IA/Proyectos/llms/chatbot/libs/hybrid_retriever.py:25\u001b[0m, in \u001b[0;36mHybridRetriever.add\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mnum_retrievers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m retriever \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrievers_list:\n\u001b[0;32m---> 25\u001b[0m         \u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m         executor\u001b[38;5;241m.\u001b[39msubmit(retriever,texts)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_thread.RLock' object"
     ]
    }
   ],
   "source": [
    "# Preparing the hybrid retrieval\n",
    "retriever = HybridRetriever(documents_=index, retrievers=[vector])\n",
    "retriever.add(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iter for al queries\n",
    "queries_info = {}\n",
    "for query in dataset.qrels_iter():\n",
    "    query_id = query[0]\n",
    "    if query[2] >=3:\n",
    "        exist_info = queries_info.get(query_id,set())\n",
    "        exist_info.add(query[1])\n",
    "        queries_info[query_id] = exist_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precistion_recall():\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for query_id, relevants_docs in queries_info.items():\n",
    "        # The text of the query\n",
    "        if query_id not in queries:\n",
    "            continue\n",
    "    \n",
    "        query = queries[query_id]\n",
    "        # Get the documents\n",
    "        retrieved_docs = set([doc['doc_id'] for doc in retriever.search(query,k=25)])\n",
    "        # relevant and retrieved\n",
    "        rr = relevants_docs.intersection(retrieved_docs)\n",
    "        # Calculating the precision\n",
    "        current_precision = len(rr)/len(retrieved_docs)\n",
    "        precision.append(current_precision)\n",
    "        # Calculating the recall\n",
    "        current_recall = len(rr)/len(relevants_docs)\n",
    "        recall.append(current_recall)\n",
    "    \n",
    "    precision = np.array(precision)\n",
    "    recall = np.array(recall)\n",
    "    \n",
    "    return precision,recall\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_thread.RLock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/usr/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\nTypeError: cannot pickle '_thread.RLock' object\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m precision,recall \u001b[38;5;241m=\u001b[39m \u001b[43mget_precistion_recall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(precision\u001b[38;5;241m.\u001b[39mmin(),np\u001b[38;5;241m.\u001b[39mmedian(precision),precision\u001b[38;5;241m.\u001b[39mmean(),precision\u001b[38;5;241m.\u001b[39mmax())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(recall\u001b[38;5;241m.\u001b[39mmin(),np\u001b[38;5;241m.\u001b[39mmedian(recall),recall\u001b[38;5;241m.\u001b[39mmean(),recall\u001b[38;5;241m.\u001b[39mmax())\n",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m, in \u001b[0;36mget_precistion_recall\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m query \u001b[38;5;241m=\u001b[39m queries[query_id]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Get the documents\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m retrieved_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# relevant and retrieved\u001b[39;00m\n\u001b[1;32m     13\u001b[0m rr \u001b[38;5;241m=\u001b[39m relevants_docs\u001b[38;5;241m.\u001b[39mintersection(retrieved_docs)\n",
      "File \u001b[0;32m/media/alejbv/Disco1/HDD Old/Carrerra/Mis Temas/DL,NLP,SRI,IA/Proyectos/llms/chatbot/libs/hybrid_retriever.py:48\u001b[0m, in \u001b[0;36mHybridRetriever.search\u001b[0;34m(self, query, k)\u001b[0m\n\u001b[1;32m     44\u001b[0m     future_results \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(retriever\u001b[38;5;241m.\u001b[39msearch,query,k) \u001b[38;5;28;01mfor\u001b[39;00m retriever \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrievers_list]\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Waiting for each of the search end for retrieving the result\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m search_results \u001b[38;5;241m=\u001b[39m [search\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m search \u001b[38;5;129;01min\u001b[39;00m future_results]     \n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Reranking the search result\u001b[39;00m\n\u001b[1;32m     51\u001b[0m combined_results \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/media/alejbv/Disco1/HDD Old/Carrerra/Mis Temas/DL,NLP,SRI,IA/Proyectos/llms/chatbot/libs/hybrid_retriever.py:48\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m     future_results \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(retriever\u001b[38;5;241m.\u001b[39msearch,query,k) \u001b[38;5;28;01mfor\u001b[39;00m retriever \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrievers_list]\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Waiting for each of the search end for retrieving the result\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m search_results \u001b[38;5;241m=\u001b[39m [\u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m search \u001b[38;5;129;01min\u001b[39;00m future_results]     \n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Reranking the search result\u001b[39;00m\n\u001b[1;32m     51\u001b[0m combined_results \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py:244\u001b[0m, in \u001b[0;36mQueue._feed\u001b[0;34m(buffer, notempty, send_bytes, writelock, reader_close, writer_close, ignore_epipe, onerror, queue_sem)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# serialize the data before acquiring the lock\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wacquire \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    246\u001b[0m     send_bytes(obj)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/reduction.py:51\u001b[0m, in \u001b[0;36mForkingPickler.dumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdumps\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m     buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetbuffer()\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_thread.RLock' object"
     ]
    }
   ],
   "source": [
    "precision,recall = get_precistion_recall()\n",
    "print(precision.min(),np.median(precision),precision.mean(),precision.max())\n",
    "print(recall.min(),np.median(recall),recall.mean(),recall.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 8 21\n",
      "25 3 17\n",
      "25 0 2\n",
      "25 0 6\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'9'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index,query \u001b[38;5;129;01min\u001b[39;00m queries\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     retrieved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_id\u001b[39m\u001b[38;5;124m'\u001b[39m]),retriever\u001b[38;5;241m.\u001b[39msearch(query,k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)))\n\u001b[0;32m----> 3\u001b[0m     valid \u001b[38;5;241m=\u001b[39m\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x:\u001b[38;5;28mint\u001b[39m(x),\u001b[43mqueries_info\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(retrieved),\u001b[38;5;28mlen\u001b[39m(valid\u001b[38;5;241m.\u001b[39mintersection(retrieved)),\u001b[38;5;28mlen\u001b[39m(valid))\n",
      "\u001b[0;31mKeyError\u001b[0m: '9'"
     ]
    }
   ],
   "source": [
    "for index,query in queries.items():\n",
    "    retrieved = set(map(lambda x: int(x['doc_id']),retriever.search(query)))\n",
    "    valid =set(map(lambda x:int(x),queries_info[index]))\n",
    "    print(len(retrieved),len(valid.intersection(retrieved)),len(valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
