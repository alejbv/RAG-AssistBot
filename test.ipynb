{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic modules\n",
    "import numpy as np\n",
    "import ir_datasets\n",
    "# The model modules\n",
    "from libs.lexical_store import LexicalStore\n",
    "from libs.vector_store import VectorStore\n",
    "from libs.retriever import RetrieverQA\n",
    "from libs.basic_document_loader import BasicIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the dataset\n",
    "# Loading the dataset\n",
    "dataset = ir_datasets.load(\"cranfield\")\n",
    "# Preparing the docs and queries\n",
    "prep_funct = lambda x: dict(doc_id=x[0],title=x[1],text=x[2],author=x[3],bib=x[4])\n",
    "docs = [doc for doc in map(prep_funct,dataset.docs_iter()) if len(doc['text'])]\n",
    "queries = {query[0]:query[1] for query in dataset.queries_iter()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the stores\n",
    "vector = VectorStore()\n",
    "lexical = LexicalStore()\n",
    "# Preparing the Indexer\n",
    "index = BasicIndexer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756919befede475689658c12f58ef014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Create Vocab:   0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1846142c552b4047a2fc56f1cbf9c4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Convert tokens to indices:   0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d1039e4ead4861a231cc018693758b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Count Tokens:   0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b96c3875b624114a2580e3721902f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Compute Scores:   0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adding the documents\n",
    "index.add_documents(docs)\n",
    "# Preparing the retrieval\n",
    "doc_text = [doc[\"text\"].strip() for doc in docs ]\n",
    "vector.add(doc_text)\n",
    "lexical.add(doc_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1398"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector._index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the retrieval\n",
    "retriever = RetrieverQA(documents_=index, stores=[vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iter for al queries\n",
    "queries_info = {}\n",
    "for query in dataset.qrels_iter():\n",
    "    query_id = query[0]\n",
    "    if query[2] >=3:\n",
    "        exist_info = queries_info.get(query_id,set())\n",
    "        exist_info.add(query[1])\n",
    "        queries_info[query_id] = exist_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precistion_recall():\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for query_id, relevants_docs in queries_info.items():\n",
    "        # The text of the query\n",
    "        if query_id not in queries:\n",
    "            continue\n",
    "    \n",
    "        query = queries[query_id]\n",
    "        # Get the documents\n",
    "        retrieved_docs = set([doc['doc_id'] for doc in retriever.search(query,k=25)])\n",
    "        # relevant and retrieved\n",
    "        rr = relevants_docs.intersection(retrieved_docs)\n",
    "        # Calculating the precision\n",
    "        current_precision = len(rr)/len(retrieved_docs)\n",
    "        precision.append(current_precision)\n",
    "        # Calculating the recall\n",
    "        current_recall = len(rr)/len(relevants_docs)\n",
    "        recall.append(current_recall)\n",
    "    \n",
    "    precision = np.array(precision)\n",
    "    recall = np.array(recall)\n",
    "    \n",
    "    return precision,recall\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.009925925925925927 0.28\n",
      "0.0 0.0 0.05116932208435476 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "precision,recall = get_precistion_recall()\n",
    "print(precision.min(),np.median(precision),precision.mean(),precision.max())\n",
    "print(recall.min(),np.median(recall),recall.mean(),recall.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 8 21\n",
      "25 3 17\n",
      "25 0 2\n",
      "25 0 6\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'9'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index,query \u001b[38;5;129;01min\u001b[39;00m queries\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     retrieved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_id\u001b[39m\u001b[38;5;124m'\u001b[39m]),retriever\u001b[38;5;241m.\u001b[39msearch(query,k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)))\n\u001b[0;32m----> 3\u001b[0m     valid \u001b[38;5;241m=\u001b[39m\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x:\u001b[38;5;28mint\u001b[39m(x),\u001b[43mqueries_info\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(retrieved),\u001b[38;5;28mlen\u001b[39m(valid\u001b[38;5;241m.\u001b[39mintersection(retrieved)),\u001b[38;5;28mlen\u001b[39m(valid))\n",
      "\u001b[0;31mKeyError\u001b[0m: '9'"
     ]
    }
   ],
   "source": [
    "for index,query in queries.items():\n",
    "    retrieved = set(map(lambda x: int(x['doc_id']),retriever.search(query)))\n",
    "    valid =set(map(lambda x:int(x),queries_info[index]))\n",
    "    print(len(retrieved),len(valid.intersection(retrieved)),len(valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
